{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-Processing-Data.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Sa2wtAG_ed7E",
        "pVj9VRH8gKA0",
        "2i_6FhoBgVXn",
        "DvCLuMGkixHk",
        "jCMibVmFjEw6",
        "Lr4aZ7bEjtmS",
        "nO3O9hvGpI46",
        "SZeo7c-nn4_c",
        "Pr8T1GGn0LTG"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPqIeUg7/BQsQcgwhkQ+Qg6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YagyanshB/SemEval-Task6-CS408/blob/main/Pre_Processing_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPipH3SRd10L"
      },
      "source": [
        "# Pre Processing of OLID 2019 Dataset:\n",
        "\n",
        "---\n",
        "\n",
        "This document will highlight the steps undertaken to pre-process and cleanse the OLID 2019 Dataset obtained from Codalab Competition. The link to the competition is [here](https://competitions.codalab.org/competitions/20011#learn_the_details).\n",
        "\n",
        "All the necessary steps have been extensively explained and it is strongly recommended to follow through with it. Additionally, we would also recommend to run the code within GoodleColab because of it's user friendly environment and robust services offered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa2wtAG_ed7E"
      },
      "source": [
        "# Importing Required Libraries:\n",
        "\n",
        "---\n",
        "\n",
        "For Data Cleansing and Data Wrangling to be carried out we need to import a certain set of libraries into our Developing Environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_vcv__IusAE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy \n",
        "from spacy.lang.en.stop_words import STOP_WORDS as stop"
      ],
      "execution_count": 570,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjjTUFkde1XA"
      },
      "source": [
        "Since the data has been uploaded within my personal Google Drive, the path to the file may vary. It is therefore strongly recommended to upload the files in your personal computer or operating system when running the source code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVj9VRH8gKA0"
      },
      "source": [
        "# Uploading & Exploring Dataset in Google Colab:\n",
        "\n",
        "---\n",
        "\n",
        "Under this section we would be uploading our datasets that we have downloaded from the CodaLab Competitions. It is extremely important to mention the right file path in order for Google Colab to upload the files in the right manner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-36EnHSv2hl",
        "outputId": "2aed5548-63c6-4e1e-a14c-3875090c41ed"
      },
      "source": [
        "# We mount our Google Drive within Google Colab. Since I have already uploaded my files on my Google Drive\n",
        "# this task becomes fairly convenient for myself. If running the program, please be sure to mount the \n",
        "# dataset on your google drive as well. \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_file = 'drive/My Drive/olid-training-v1.0.tsv'\n",
        "\n",
        "test_file_a = 'drive/My Drive/testset-levela.tsv' \n",
        "test_labels_a = 'drive/My Drive/labels-levela.csv' \n",
        "\n",
        "test_labels_b = 'drive/My Drive/labels-levelb.csv' \n",
        "test_file_b = 'drive/My Drive/testset-levelb.tsv' \n",
        "\n",
        "test_file_c = 'drive/My Drive/testset-levelc.tsv' \n",
        "test_labels_c = 'drive/My Drive/labels-levelc.csv' \n",
        "\n",
        "# Within the Code below, we re run the code to ensure that our files have been\n",
        "# mounted in the right manner. It is imperative to have the link to the directory\n",
        "# sent correctly; else the files won't be loaded."
      ],
      "execution_count": 571,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WzP-dmwv68E",
        "outputId": "176cf167-edd1-4970-b61e-f8bbddff2c2a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('drive/My Drive/olid-training-v1.0.tsv', sep='\\t')\n",
        "\n",
        "print (df) # Skimming and looking at the first initial rows of our dataset."
      ],
      "execution_count": 572,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id  ... subtask_c\n",
            "0      86426  ...       NaN\n",
            "1      90194  ...       IND\n",
            "2      16820  ...       NaN\n",
            "3      62688  ...       NaN\n",
            "4      43605  ...       NaN\n",
            "...      ...  ...       ...\n",
            "13235  95338  ...       IND\n",
            "13236  67210  ...       NaN\n",
            "13237  82921  ...       OTH\n",
            "13238  27429  ...       NaN\n",
            "13239  46552  ...       NaN\n",
            "\n",
            "[13240 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WohB6eLPxDah",
        "outputId": "5b5a2991-9d03-4e28-d897-68c785193177"
      },
      "source": [
        "df.shape # It tells us the dimensions of our dataset that is 13240 ROWS spread across 5 COLUMNS."
      ],
      "execution_count": 573,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13240, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 573
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i_6FhoBgVXn"
      },
      "source": [
        "# Categorisation of Tweets According to Sub-Tasks:\n",
        "\n",
        "---\n",
        "\n",
        "After having uploaded the OLID 2019 Dataset, we explore and have a high-level approach of looking into how the tweets have been classified and categorised based on the three different sub-tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqgaKn0cxMOR",
        "outputId": "2fe2d032-fa36-4eea-d4d3-7e1d6896a9de"
      },
      "source": [
        "df['subtask_a'].value_counts() # Categorisation of tweets into Offensive and Not Offensive Category"
      ],
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NOT    8840\n",
              "OFF    4400\n",
              "Name: subtask_a, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 574
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rty8p-frxbrY",
        "outputId": "afcb443d-008a-47c5-d2a5-ce38f3e7ea0e"
      },
      "source": [
        "df['subtask_b'].value_counts() # Categorisation of tweets into Targeted Insult and Untargeted Insult."
      ],
      "execution_count": 575,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TIN    3876\n",
              "UNT     524\n",
              "Name: subtask_b, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 575
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8A7rh-pxlhF",
        "outputId": "ba5aa7ff-900c-4e02-cbd8-a7dea2fa4901"
      },
      "source": [
        "df['subtask_c'].value_counts() # Categorisation of tweets into Offense targeted towards Individual, Group or Other Category."
      ],
      "execution_count": 576,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IND    2407\n",
              "GRP    1074\n",
              "OTH     395\n",
              "Name: subtask_c, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 576
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvCLuMGkixHk"
      },
      "source": [
        "# Lowercasing All Tweets Present:\n",
        "\n",
        "---\n",
        "\n",
        "As human beings we have the ability to express different emotions by capitalising on text messages or tweets. The machine doesn't have the necessary ability to read emotions due to which we would be lower casing all the tweets from our OLID 2019 Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OVUH_Y_g8wdn",
        "outputId": "07780d10-4421-4304-dca9-bc69b894c024"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 577,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>33006</td>\n",
              "      <td>@USER @USER He is probably dying due to dog fu...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5128</th>\n",
              "      <td>27384</td>\n",
              "      <td>@USER OK, on second thought, Antifa wasn't eve...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4651</th>\n",
              "      <td>63857</td>\n",
              "      <td>@USER From the liberal media.....Yea...we shou...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10359</th>\n",
              "      <td>63019</td>\n",
              "      <td>@USER Funny.  She had no problem sleeping her ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5195</th>\n",
              "      <td>50275</td>\n",
              "      <td>@USER Look at how shamelessly liberals lie to ...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>GRP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... subtask_c\n",
              "5191   33006  ...       NaN\n",
              "5128   27384  ...       NaN\n",
              "4651   63857  ...       NaN\n",
              "10359  63019  ...       NaN\n",
              "5195   50275  ...       GRP\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 577
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpvqHTrVZQzH"
      },
      "source": [
        "x = 'LOCKDOWN SUCKS'"
      ],
      "execution_count": 578,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IqWWwlexZYER",
        "outputId": "1e9fd6d7-249b-4866-8dd0-4ffc1270f060"
      },
      "source": [
        "x.lower()"
      ],
      "execution_count": 579,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'lockdown sucks'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 579
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOMpDeuXZiWh"
      },
      "source": [
        "df['processed_tweet'] = df['tweet'].apply(lambda x: str(x).lower())"
      ],
      "execution_count": 580,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qP40cO2TZt0n",
        "outputId": "07cd5ce6-af87-46c0-b8a3-2bcbf49dcd29"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 581,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>processed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11154</th>\n",
              "      <td>31511</td>\n",
              "      <td>#boom @USER maybe that book deal isnt such a g...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#boom @user maybe that book deal isnt such a g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3808</th>\n",
              "      <td>95018</td>\n",
              "      <td>@USER He will never live this down! You know h...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@user he will never live this down! you know h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8261</th>\n",
              "      <td>36520</td>\n",
              "      <td>.@USER won this round. Yucker ALWAYS interrupt...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "      <td>.@user won this round. yucker always interrupt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12864</th>\n",
              "      <td>82767</td>\n",
              "      <td>@USER bakkt is doing what an ETF would have do...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "      <td>@user bakkt is doing what an etf would have do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9766</th>\n",
              "      <td>92852</td>\n",
              "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@user @user @user @user @user @user @user @use...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                    processed_tweet\n",
              "11154  31511  ...  #boom @user maybe that book deal isnt such a g...\n",
              "3808   95018  ...  @user he will never live this down! you know h...\n",
              "8261   36520  ...  .@user won this round. yucker always interrupt...\n",
              "12864  82767  ...  @user bakkt is doing what an etf would have do...\n",
              "9766   92852  ...  @user @user @user @user @user @user @user @use...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 581
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCMibVmFjEw6"
      },
      "source": [
        "# Expanding Contracted Words:\n",
        "\n",
        "---\n",
        "\n",
        "A contraction is a shortened form of a word (or group of words) that omits certain letters or sounds. In most contractions, an apostrophe represents the missing letters. The most common contractions are made up of verbs, auxiliaries, or modals attached to other words: He would=He'd. I have=I've.\n",
        "\n",
        "In order for our model to understand what a sentence means or has to offer it is important to realise the context of our sentence or tweet. For this purpose, we have to expand on the different contracting words we as users so conveniently use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FwFObGQaBpR"
      },
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how does\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\" u \": \" you \",\n",
        "\" ur \": \" your \",\n",
        "\" n \": \" and \",\n",
        "\"you're\": \"you are\"}\n"
      ],
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C47rENVsaGxq"
      },
      "source": [
        "x = \" i'm don't he'll\" # I am do not he will"
      ],
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE2d1M1NaS1i"
      },
      "source": [
        "def cont_to_exp(x):\n",
        "  if type(x) is str:\n",
        "    for key in contractions:\n",
        "        value = contractions[key]\n",
        "        x = x.replace(key,value)\n",
        "    return x\n",
        "\n",
        "  else:\n",
        "    return x"
      ],
      "execution_count": 584,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ByJZ4pNxbPsm",
        "outputId": "23c30048-2614-4187-83d8-8d47998e1684"
      },
      "source": [
        "cont_to_exp(x)"
      ],
      "execution_count": 585,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' i am do not he will'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 585
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFXMpc9jbpo2",
        "outputId": "c4e83641-5720-4cbf-b023-00262a16058f"
      },
      "source": [
        "%%timeit\n",
        "df['processed_tweet'] = df['processed_tweet'].apply(lambda x: cont_to_exp(x))"
      ],
      "execution_count": 586,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 353 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U5YJKj4hb_Vo",
        "outputId": "05fbd497-71f7-4bbf-d3a1-94f204ca3435"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 587,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>processed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10151</th>\n",
              "      <td>96943</td>\n",
              "      <td>@USER @USER @USER @USER @USER @USER so stronge...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@user @user @user @user @user @user so stronge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>67365</td>\n",
              "      <td>@USER @USER I have. Its horse dung. She can't ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@user @user i have. its horse dung. she cannot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3901</th>\n",
              "      <td>46418</td>\n",
              "      <td>@USER Well, there's that one idiot you keep th...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "      <td>@user well, there is that one idiot you keep t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11017</th>\n",
              "      <td>86899</td>\n",
              "      <td>@USER He is spending your contributions. Vote ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@user he is spending your contributions. vote ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12307</th>\n",
              "      <td>24912</td>\n",
              "      <td>@USER @USER He/she deserves those tattoos. Hop...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@user @user he/she deserves those tattoos. hop...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                    processed_tweet\n",
              "10151  96943  ...  @user @user @user @user @user @user so stronge...\n",
              "1496   67365  ...  @user @user i have. its horse dung. she cannot...\n",
              "3901   46418  ...  @user well, there is that one idiot you keep t...\n",
              "11017  86899  ...  @user he is spending your contributions. vote ...\n",
              "12307  24912  ...  @user @user he/she deserves those tattoos. hop...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 587
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr4aZ7bEjtmS"
      },
      "source": [
        "# Removal of @USER Mentions:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8IWl88hL0PG",
        "outputId": "26384c44-149b-4401-e1df-3d9b1b3e8412"
      },
      "source": [
        "df['processed_tweet']"
      ],
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         she should ask a few native americans what th...\n",
              "1          go home you’re drunk!!!  #maga #trump2020 👊🇺...\n",
              "2        amazon is investigating chinese employees who ...\n",
              "3         someone should havetaken\" this piece of shit ...\n",
              "4          obama wanted liberals &amp; illegals to move...\n",
              "                               ...                        \n",
              "13235     sometimes i get strong vibes from people and ...\n",
              "13236    benidorm ✅  creamfields ✅  maga ✅   not too sh...\n",
              "13237     and why report this garbage.  we do not give ...\n",
              "13238                                                pussy\n",
              "13239    #spanishrevenge vs. #justice #humanrights and ...\n",
              "Name: processed_tweet, Length: 13240, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 590
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elxpo9DKjzrX"
      },
      "source": [
        "df[df['processed_tweet'].str.contains('@user')]\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('@user','') # remove '@user' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('user','') # remove '@user' tokens\n",
        "\n",
        "# We need to bear in mind to use a lower cased @user since we have lowercased our processed tweets.\n",
        "# This shows us that there are 12274 tweets containing @user mentions .\n",
        "# This information would be irrelevant in training our machine learning model and we decided to make it redundant."
      ],
      "execution_count": 591,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy5hVJcQ_V7Q",
        "outputId": "94dc8c18-6694-47e3-a723-bd4bd456df0d"
      },
      "source": [
        "test_1 = df['processed_tweet'].str.contains('@user')\n",
        "test_1a = df['processed_tweet'].str.contains('user')\n",
        "\n",
        "test_1.value_counts() \n",
        "test_1a.value_counts()\n",
        "\n",
        "# On testing we notice that there are no tweets that have any @user mentions.\n",
        "# This showcases that our tweets has completed this processing step.\n"
      ],
      "execution_count": 592,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    13240\n",
              "Name: processed_tweet, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 592
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO3O9hvGpI46"
      },
      "source": [
        "#Removal of URLS:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R-RESIwpX47"
      },
      "source": [
        "import re # Importing the Regular Experssion library"
      ],
      "execution_count": 593,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ8v3QHlqq7E"
      },
      "source": [
        "  df['processed_tweet'] = df['processed_tweet'].str.replace('url','') # remove 'url' tokens"
      ],
      "execution_count": 594,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wt1wKn_rfTR",
        "outputId": "121dd4a7-ec58-42e9-f179-cd6aea9182ff"
      },
      "source": [
        "df['processed_tweet'].head(10)"
      ],
      "execution_count": 595,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     she should ask a few native americans what th...\n",
              "1      go home you’re drunk!!!  #maga #trump2020 👊🇺🇸👊 \n",
              "2    amazon is investigating chinese employees who ...\n",
              "3     someone should havetaken\" this piece of shit ...\n",
              "4      obama wanted liberals &amp; illegals to move...\n",
              "5                          liberals are all kookoo !!!\n",
              "6                                 oh noes! tough shit.\n",
              "7     was literally just talking about this lol all...\n",
              "8                                 buy more icecream!!!\n",
              "9     canada doesn’t need another cuck! we already ...\n",
              "Name: processed_tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 595
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZeo7c-nn4_c"
      },
      "source": [
        "#Removal of Emojis Promoting Profanity:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY3FlLrskhp_"
      },
      "source": [
        "emoji_dict = {'❤️': ' love ',\n",
        "                       '❤️' : ' love ',\n",
        "                       '❤' : ' love ',\n",
        "                       '😘' : ' kisses ',\n",
        "                      '😭' : ' cry ',\n",
        "                      '💪' : ' strong ',\n",
        "                      '🌍' : ' earth ',\n",
        "                      '💰' : ' money ',\n",
        "                      '👍' : ' ok ',\n",
        "                       '👌' : ' ok ',\n",
        "                      '😡' : ' angry ',\n",
        "                      '🍆' : ' dick ',\n",
        "                      '🤣' : ' haha ',\n",
        "                      '😂' : ' haha ',\n",
        "                      '🖕' : ' fuck you ',\n",
        "                      '👊' : ' punch you',}"
      ],
      "execution_count": 596,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAKiKvFWlWpC"
      },
      "source": [
        "df['processed_tweet'] = df['processed_tweet'].str.replace('😭','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('❤','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('🤣','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('🍆','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('🖕','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('😂','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('😡','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('👌','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('👍','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('💰','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('🌍','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('💪','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('😘','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('❤️','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('❤️','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('👊','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('🇺🇸','') # remove 'emoji' tokens\n",
        "df['processed_tweet'] = df['processed_tweet'].str.replace('✅','') # remove 'emoji' tokens"
      ],
      "execution_count": 597,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9va5ponznjXa",
        "outputId": "8f7e0237-0b59-48a1-b920-4206985fd15d"
      },
      "source": [
        "df['processed_tweet'].head(10)"
      ],
      "execution_count": 598,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     she should ask a few native americans what th...\n",
              "1          go home you’re drunk!!!  #maga #trump2020  \n",
              "2    amazon is investigating chinese employees who ...\n",
              "3     someone should havetaken\" this piece of shit ...\n",
              "4      obama wanted liberals &amp; illegals to move...\n",
              "5                          liberals are all kookoo !!!\n",
              "6                                 oh noes! tough shit.\n",
              "7     was literally just talking about this lol all...\n",
              "8                                 buy more icecream!!!\n",
              "9     canada doesn’t need another cuck! we already ...\n",
              "Name: processed_tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 598
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr8T1GGn0LTG"
      },
      "source": [
        "# Removal of Special Characters\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZpVg52Bdmm60",
        "outputId": "f25a15dd-fdd8-4687-9728-0dbb2104c3ff"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 599,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>processed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>94619</td>\n",
              "      <td>@USER melbourne didnt like me can I join you i...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>melbourne didnt like me can i join you instea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6598</th>\n",
              "      <td>67185</td>\n",
              "      <td>There is only ONE reason why Christine Blasey ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is only one reason why christine blasey ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8844</th>\n",
              "      <td>46787</td>\n",
              "      <td>@USER Dear Andrew I saw the endorsement by Cor...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "      <td>dear andrew i saw the endorsement by cory boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13123</th>\n",
              "      <td>94883</td>\n",
              "      <td>@USER We need to stop expecting liberals to ac...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>we need to stop expecting liberals to act rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11008</th>\n",
              "      <td>12496</td>\n",
              "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                    processed_tweet\n",
              "1482   94619  ...   melbourne didnt like me can i join you instea...\n",
              "6598   67185  ...  there is only one reason why christine blasey ...\n",
              "8844   46787  ...   dear andrew i saw the endorsement by cory boo...\n",
              "13123  94883  ...   we need to stop expecting liberals to act rea...\n",
              "11008  12496  ...                                                ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 599
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw3qJzMEn8MZ"
      },
      "source": [
        "x = 'thanks for proving democrats can’t let thei...'"
      ],
      "execution_count": 600,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V2dnZv-WoGRf",
        "outputId": "016a4a0b-9800-4c3e-8262-3e2a898a0a85"
      },
      "source": [
        "re.sub('[^a-zA-z0-9\\s]',\"\",x)"
      ],
      "execution_count": 601,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thanks for proving democrats cant let thei'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 601
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "debdNJ05KzOr"
      },
      "source": [
        "df['processed_tweet'] = df['processed_tweet'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]',\"\",x))"
      ],
      "execution_count": 602,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riQimZTtpXXn",
        "outputId": "398d724c-7c0b-4f81-8553-a88a467f5361"
      },
      "source": [
        "df['processed_tweet'].head(10)"
      ],
      "execution_count": 603,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     she should ask a few native americans what th...\n",
              "1                go home youre drunk  maga trump2020  \n",
              "2    amazon is investigating chinese employees who ...\n",
              "3     someone should havetaken this piece of shit t...\n",
              "4      obama wanted liberals amp illegals to move i...\n",
              "5                             liberals are all kookoo \n",
              "6                                   oh noes tough shit\n",
              "7     was literally just talking about this lol all...\n",
              "8                                    buy more icecream\n",
              "9     canada doesnt need another cuck we already ha...\n",
              "Name: processed_tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 603
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2vyijSuwA24"
      },
      "source": [
        "# Tokenisation of Tweets\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ywacIOwC9e"
      },
      "source": [
        "df['processed_tweet'] = df['processed_tweet'].apply(lambda x: x.split())"
      ],
      "execution_count": 604,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "JbYvHXq4wOar",
        "outputId": "cc377c4a-4a10-4e13-dfd9-afa35d908283"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 605,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>processed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8889</th>\n",
              "      <td>30602</td>\n",
              "      <td>@USER If you want more shooting just call G So...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[if, you, want, more, shooting, just, call, g,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11906</th>\n",
              "      <td>11777</td>\n",
              "      <td>A 5th columnist always imagines himself as a p...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>GRP</td>\n",
              "      <td>[a, 5th, columnist, always, imagines, himself,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2895</th>\n",
              "      <td>65180</td>\n",
              "      <td>TRYING TO HIDE ALL THE EVIDENCE 😂😎✍👀 #MAGA #QA...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[trying, to, hide, all, the, evidence, maga, q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>14407</td>\n",
              "      <td>@USER Brown like you</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[brown, like, you]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12641</th>\n",
              "      <td>27235</td>\n",
              "      <td>@USER Um bc she is??????</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[um, bc, she, is]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                    processed_tweet\n",
              "8889   30602  ...  [if, you, want, more, shooting, just, call, g,...\n",
              "11906  11777  ...  [a, 5th, columnist, always, imagines, himself,...\n",
              "2895   65180  ...  [trying, to, hide, all, the, evidence, maga, q...\n",
              "367    14407  ...                                 [brown, like, you]\n",
              "12641  27235  ...                                  [um, bc, she, is]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 605
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l79lYUobEnHY"
      },
      "source": [
        "# Stemming of Tweets\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRIrH7AeaaUj",
        "outputId": "6599455e-34cd-43aa-fc59-5ddfd25bd9d6"
      },
      "source": [
        "df['processed_tweet'].head(10)"
      ],
      "execution_count": 562,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     she should ask a few native americans what th...\n",
              "1                go home youre drunk  maga trump2020  \n",
              "2    amazon is investigating chinese employees who ...\n",
              "3     someone should havetaken this piece of shit t...\n",
              "4      obama wanted liberals amp illegals to move i...\n",
              "5                             liberals are all kookoo \n",
              "6                                   oh noes tough shit\n",
              "7     was literally just talking about this lol all...\n",
              "8                                    buy more icecream\n",
              "9     canada doesnt need another cuck we already ha...\n",
              "Name: processed_tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 562
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aDoAwzNajSz"
      },
      "source": [
        "x = 'she should ask a few native americans what th...'"
      ],
      "execution_count": 563,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z87aUL82ahfn",
        "outputId": "15f02735-bb02-4af9-b021-f27076cbb55e"
      },
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "df['processed_tweet'] = df['processed_tweet'].apply(lambda x: [stemmer.stem(i) for i in x]) # stemming"
      ],
      "execution_count": 569,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [@, U, S, E, R,  , S, h, e,  , s, h, o, u, l, ...\n",
              "1    [@, U, S, E, R,  , @, U, S, E, R,  , G, o,  , ...\n",
              "2    [A, m, a, z, o, n,  , i, s,  , i, n, v, e, s, ...\n",
              "3    [@, U, S, E, R,  , S, o, m, e, o, n, e,  , s, ...\n",
              "4    [@, U, S, E, R,  , @, U, S, E, R,  , O, b, a, ...\n",
              "Name: tokenized_tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 569
        }
      ]
    }
  ]
}